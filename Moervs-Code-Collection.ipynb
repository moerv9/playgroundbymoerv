{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moervs Code Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# python snippets\n",
    "~/Library/Application Support/Code/User/snippets/python.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'-'\tsolid line style\n",
    "'--'\tdashed line style\n",
    "'-.'\tdash-dot line style\n",
    "':'\tdotted line style\n",
    "'.'\tpoint marker\n",
    "','\tpixel marker\n",
    "'o'\tcircle marker\n",
    "'v'\ttriangle_down marker\n",
    "'^'\ttriangle_up marker\n",
    "'<'\ttriangle_left marker\n",
    "'>'\ttriangle_right marker\n",
    "'1'\ttri_down marker\n",
    "'2'\ttri_up marker\n",
    "'3'\ttri_left marker\n",
    "'4'\ttri_right marker\n",
    "'s'\tsquare marker\n",
    "'p'\tpentagon marker\n",
    "'*'\tstar marker\n",
    "'h'\thexagon1 marker\n",
    "'H'\thexagon2 marker\n",
    "'+'\tplus marker\n",
    "'x'\tx marker\n",
    "'D'\tdiamond marker\n",
    "'d'\tthin_diamond marker\n",
    "'|'\tvline marker\n",
    "'_'\thline marker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Offset aliases](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.tick_params(which='major', width=1.00)\n",
    "ax.tick_params(which='major', length=5)\n",
    "ax.tick_params(which='minor', width=0.75)\n",
    "ax.tick_params(which='minor', length=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multicolor\n",
    "# t = np.linspace(0, 2 * np.pi, 46)\n",
    "# x = df_mean_byMinute.index\n",
    "# y = df_mean_byMinute[\"Sentiment Score\"]\n",
    "\n",
    "# cmap, norm = mcolors.from_levels_and_colors([0,2,5,6], ['red', 'blue', 'green'])\n",
    "# plt.scatter(x, y, c=t, cmap=cmap, norm=norm)\n",
    "\n",
    "# dydx = np.cos(0.5 * (y[:-1] + y[1:]))  # first derivative\n",
    "# points = np.array([x, y]).T.reshape(-1, 1, 2)\n",
    "# fig, axs = plt.subplots(2, 1, sharex=True, sharey=True)\n",
    "# segments = np.concatenate([points[:-1], points[1:]], axis=1)\n",
    "# # Use a boundary norm instead\n",
    "# cmap = ListedColormap(['r', 'g', 'b'])\n",
    "# norm = BoundaryNorm([-1, -0.5, 0.5, 1], cmap.N)\n",
    "# lc = LineCollection(segments, cmap=cmap, norm=norm)\n",
    "# lc.set_array(dydx)\n",
    "# lc.set_linewidth(2)\n",
    "# line = axs[1].add_collection(lc)\n",
    "# fig.colorbar(line, ax=axs[1])\n",
    "\n",
    "# axs[0].set_xlim(x.min(), x.max())\n",
    "# axs[0].set_ylim(-1.1, 1.1)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two plots in one try\n",
    "from matplotlib.collections import LineCollection\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "\n",
    "# CHARTS\n",
    "def show_charts(df, data):\n",
    "    #setup\n",
    "    fig, axs = plt.subplots(3,1,sharex=True,constrained_layout=True)#figsize=(10, 4))\n",
    "    plt.rcParams['font.size'] = '8'\n",
    "    # plt.rcParams[\"figure.figsize\"] = (6,4)\n",
    "    #colors\n",
    "    for nn,ax in enumerate(axs):\n",
    "        axs[nn].title.set_color(\"white\")\n",
    "        axs[nn].xaxis.label.set_color('white') \n",
    "        axs[nn].yaxis.label.set_color('white')\n",
    "        axs[nn].tick_params(axis='x', colors='white',labelrotation=30)\n",
    "        axs[nn].tick_params(axis='y', colors='white')\n",
    "        axs[nn].spines[\"left\"].set_color('white')\n",
    "        axs[nn].spines[\"bottom\"].set_color('white') \n",
    "        axs[nn].spines[\"top\"].set_alpha(0)\n",
    "        axs[nn].spines[\"right\"].set_alpha(0)\n",
    "        axs[nn].set_facecolor((0,0,0,0))\n",
    "        axs[nn].xaxis.set_major_locator(date_locator)\n",
    "        axs[nn].xaxis.set_minor_locator(date_locator)\n",
    "        axs[nn].xaxis.set_major_formatter(formatter)\n",
    "    fig.patch.set_alpha(0)\n",
    "    \n",
    "    #set labels\n",
    "    #axs[1].set_title(f\"Average Sentiment for {intervals} Min. Intervals\")\n",
    "    axs[1].set_ylabel(\"Sentiment Score\")\n",
    "    axs[0].set_xlabel(\"Time\")\n",
    "    axs[0].set_ylabel(\"Price ($)\")\n",
    "    #axs[2].set_ylabel(\"Amount of Tweets\")\n",
    "    x1 = data.index\n",
    "    y1 = data.Close    \n",
    "    buy_marker, sell_marker,_,_ = get_timestamps_for_trades(df,x1)\n",
    "    #first plot for btc price\n",
    "    axs[0].set_title(f\"Sent > 0.2 => Buy\")\n",
    "    axs[0].plot(x1,y1,\"^\",label=\"buy\",color=cmap(0.25),markersize=4,markevery=buy_marker)\n",
    "    axs[0].plot(x1,y1,\"v\",label=\"sell\",color=cmap(0.8),markersize=4,markevery=sell_marker)\n",
    "    axs[0].plot(x1,y1,label=\"BTC Price\",color=\"w\",linewidth=1,markersize=3)\n",
    "    \n",
    "    #third plot for sentiment\n",
    "    x = df.index\n",
    "    y = df[\"avg\"]\n",
    "    trade_signal = df[\"side\"]\n",
    "    axs[1].plot(x,y,linestyle=\":\", label=\"Sentiment\",color=\"orange\", markersize=2,linewidth=1)\n",
    "    axs[1].axhline(y=0.2,linestyle=\":\",color=\"red\",linewidth=0.5)   \n",
    "    axs[0].legend()\n",
    "    \n",
    "    #plt.tight_layout()\n",
    "    #axs[2].plot(x,df[\"Total Tweets\"],linestyle=\":\", label=\"Tweets\",color=\"yellow\", markersize=2,linewidth=1)\n",
    "    st.pyplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sell_vals = []\n",
    "buy_vals = []\n",
    "plot_buy_marker  = []\n",
    "plot_sell_marker  = []\n",
    "buy_time = []\n",
    "sell_time = []\n",
    "\n",
    "def get_timestamps_for_trades(avg_count_df,btc_timestamps):\n",
    "    avg_count_df.sort_index(ascending=False)\n",
    "    for i in range(len(avg_count_df)):\n",
    "        if avg_count_df[\"avg\"].values[i] > 0.2:\n",
    "            buy_vals.append(avg_count_df.index[i])#[Timestamp('2022-08-09 14:00:00'), ,...]\n",
    "        else:\n",
    "            sell_vals.append(avg_count_df.index[i])\n",
    "    for i in range(len(btc_timestamps)):\n",
    "        if btc_timestamps.values[i] in buy_vals:\n",
    "            buy_time.append(pd.to_datetime(btc_timestamps.values[i],utc=True))\n",
    "            plot_buy_marker.append(i) #[1, 2, 7, 8, 10, 11, 12, 13, ...]\n",
    "        elif btc_timestamps.values[i] in sell_vals:\n",
    "            plot_sell_marker.append(i)\n",
    "            sell_time.append(pd.to_datetime(btc_timestamps.values[i],utc=True))\n",
    "    #df = pd.Series(data=True,index=buy_time)\n",
    "    \n",
    "    #print(pd.Series(buy_time))\n",
    "    #price_for_date_df = [x.strftime(\"%d %B, %Y %H:%M:%S\") for x in buy_time] #['05 August, 2022 17:00:00', ...]\n",
    "    #price_for_date_df = getDateData(\"BTCUSDT\",\"1h\",price_for_date_df[0],price_for_date_df[1])\n",
    "    #print(price_for_date_df.to_string())\n",
    "    \n",
    "    return plot_buy_marker, plot_sell_marker,buy_time,sell_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = [7, 57, 121, 192, 123, 240, 546]\n",
    "\n",
    "for i, v in enumerate(values):\n",
    "    print(i, v)\n",
    "    \n",
    "    # for i, v in enumerate(zip(x,y)):\n",
    "        #axs[0].annotate(str(v[0]), xy=(i,v[1]),color=\"white\",label=\"sent\")\n",
    "        #axs[0].annotate(str(v[1])[0:4], xy=(v[0], v[2]),xycoords= \"data\",color=\"w\",fontsize=4)#,xytext=(-7,7), textcoords='offset points') #\"%d\" %v\n",
    "    # axs[2].annotate(\n",
    "    #     f'Example Sentiment: {y}',\n",
    "    #     xy=(x, y), arrowprops=dict(arrowstyle='->'), xytext=(15, -10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        '''\n",
    "        #99ff99 = green v/very positive\n",
    "        #66b3ff = lightblue\n",
    "        #ff9999 = rosa\n",
    "        #ffcc99 = orange\n",
    "        #ff99cc = red\n",
    "        #f7ff99 = yellow\n",
    "        #FEE08A = neutral\n",
    "        #ff9999 = negative\n",
    "        #B2172B = very negative\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 108x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Pie chart\n",
    "labels = ['']\n",
    "sent = 0.145\n",
    "if sent > 0.2:\n",
    "    sizes = [sent,1-sent]   \n",
    "    colors = ['green']\n",
    "    startangle= 90\n",
    "else: \n",
    "    sizes = [-sent,1+sent]\n",
    "    colors = [\"red\"]\n",
    "    startangle= -180\n",
    "#colors\n",
    "\n",
    "fig1, ax1 = plt.subplots(figsize=(1.5, 3))\n",
    "\n",
    "ax1.title.set_color(\"white\")\n",
    "ax1.xaxis.label.set_color('white') \n",
    "ax1.yaxis.label.set_color('white')\n",
    "ax1.tick_params(axis='y', colors='white')\n",
    "ax1.tick_params(axis='x', colors='white')\n",
    "ax1.spines[\"left\"].set_color('white')\n",
    "ax1.spines[\"top\"].set_alpha(0)\n",
    "ax1.spines[\"right\"].set_alpha(0)\n",
    "ax1.spines[\"bottom\"].set_alpha(0)\n",
    "ax1.set_facecolor((0,0,0,0))\n",
    "#ax1.pie(sizes, colors=colors, startangle=startangle)\n",
    "ax1.set_ylim(-1,1)\n",
    "\n",
    "plots = ax1.bar(0.2,sent, color =colors)\n",
    "#ax1.annotate(sent,ha='center', va='center',xytext=(0, 8),\n",
    "                    #textcoords='offset points', )\n",
    "ax1.bar_label(plots,padding=5,color=\"white\",fontsize=12)\n",
    "\n",
    "#draw circle\n",
    "# centre_circle = plt.Circle((0,0),0.70,fc='k')\n",
    "# fig = plt.gcf()\n",
    "# fig.gca().add_artist(centre_circle)\n",
    "# Equal aspect ratio ensures that pie is drawn as a circle\n",
    "# ax1.axis('equal')  \n",
    "# ax1.text(-0.2,.2,sent,color=\"white\",fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not hide_Charts:\n",
    "    st.subheader(\"Charts\")\n",
    "    # if st.checkbox(\"Show only last 24h\"):\n",
    "    #     lookback_timeframe = 24\n",
    "    # else:\n",
    "    #     lookback_timeframe = 96\n",
    "    # Get price data for bitcoin\n",
    "    lookback_timeframe = 24\n",
    "    data = getminutedata(\"BTCUSDT\",intervals,lookback_timeframe)\n",
    "    time.sleep(1)\n",
    "    #show_charts(split_DF_by_time(resampled_mean_tweetcount,lookback_timeframe,False),data)\n",
    "    st.markdown(\"---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    for x,y in zip(trade_timeperiods.index, df_avg):\n",
    "\n",
    "        label = \"{:.2f}\".format(y)\n",
    "        print(x)\n",
    "        print(label)\n",
    "\n",
    "        ax1.annotate(label, # this is the text\n",
    "                    (x,y), # these are the coordinates to position the label\n",
    "                    textcoords=\"offset points\", # how to position the text\n",
    "                    xytext=(0,10), # distance from text to points (x,y)\n",
    "                    ha='center',\n",
    "                    color=\"white\"\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#TODO\n",
    "def visualise_timeperiods(df):\n",
    "    time_periods ,avg, total_tweets,signal = df.index,df[\"Avg\"], df[\"Total Tweets\"],df[\"Signal\"]\n",
    "    fig1, ax1 = plt.subplots()\n",
    "    ax1.title.set_color(\"white\")\n",
    "    ax1.xaxis.label.set_color('white') \n",
    "    ax1.yaxis.label.set_color('white')\n",
    "    ax1.tick_params(axis='x', colors='white',labelrotation=30)\n",
    "    ax1.tick_params(axis='y', colors='white')\n",
    "    ax1.spines[\"left\"].set_color('white')\n",
    "    ax1.spines[\"bottom\"].set_color('white')\n",
    "    ax1.spines[\"top\"].set_alpha(0)\n",
    "    ax1.spines[\"right\"].set_alpha(0)\n",
    "    ax1.set_facecolor((0,0,0,0))\n",
    "    fig1.patch.set_alpha(0)\n",
    "    \n",
    "    plot1 = ax1.plot(time_periods,avg,label=\"Avg\",color=\"red\")\n",
    "    plot2 = ax1.plot(time_periods,total_tweets,label=\"Total Tweets\",color=\"cyan\")\n",
    "    ax1.legend()\n",
    "    st.pyplot(fig1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Open      High       Low     Close     Volume\n",
      "Time                                                                  \n",
      "2022-08-17 14:00:00  23746.65  23747.91  23728.86  23743.53  110.15727\n",
      "2022-08-17 14:01:00  23743.53  23760.09  23735.18  23759.22   84.61940\n",
      "2022-08-17 14:02:00  23760.09  23760.38  23743.77  23747.17   68.60458\n",
      "2022-08-17 14:03:00  23747.92  23753.01  23723.01  23724.97  106.61761\n",
      "2022-08-17 14:04:00  23726.01  23739.66  23720.03  23729.27  117.75679\n",
      "...                       ...       ...       ...       ...        ...\n",
      "2022-08-17 21:56:00  23274.80  23280.69  23261.72  23265.75  127.68311\n",
      "2022-08-17 21:57:00  23264.37  23279.68  23262.70  23270.71   96.70607\n",
      "2022-08-17 21:58:00  23272.11  23292.11  23270.70  23291.21   95.62044\n",
      "2022-08-17 21:59:00  23291.04  23294.03  23271.18  23275.04  115.32825\n",
      "2022-08-17 22:00:00  23276.89  23288.00  23263.20  23265.36   98.09844\n",
      "\n",
      "[481 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import pandas as pd\n",
    "from binance import Client\n",
    "from binance.enums import *\n",
    "import sys\n",
    "sys.path.insert(0,\"/Users/marvinottersberg/Documents/GitHub/sentiment\")\n",
    "from config import ConfigBinance\n",
    "conf = ConfigBinance().getKeys(False)\n",
    "\n",
    "#Init Binance Client\n",
    "client = Client(conf[0],conf[1])\n",
    "\n",
    "\n",
    "#tickers = client.get_ticker(\"BTC\")\n",
    "#balance = client.get_asset_balance(asset='BTC')[\"free\"]\n",
    "\n",
    "#depth = client.get_order_book(symbol='BTCUSDT')\n",
    "# fees = client.get_trade_fee(symbol='BTCUSDT')\n",
    "tickers = client.get_ticker()\n",
    "# orders = client.get_all_orders(symbol='BTCUSDT', limit=10)\n",
    "#print(f\"Account Balance: {balance} BTC\")\n",
    "# btc_price = client.get_symbol_ticker(symbol=\"BTCUSDT\")[\"price\"]\n",
    "# print(f\"Latest BTC Price: {btc_price} USDT\")\n",
    "#print(depth)\n",
    "#print(fees)\n",
    "#print(tickers[0])\n",
    "#print(orders)\n",
    "date = \"2022-08-17T16:00:38\"\n",
    "#print(date)\n",
    "get_this_date = pd.to_datetime(date).strftime(\"%Y-%m-%d %H:%M:00\")\n",
    "##print(get_this_date)\n",
    "date1 = pd.to_datetime(date) - timedelta(hours=4)\n",
    "date2 = pd.to_datetime(date) + timedelta(hours=4)\n",
    "\n",
    "date1 = date1.strftime(\"%d %B, %Y %H:%M\")\n",
    "date2 = date2.strftime(\"%d %B, %Y %H:%M\")\n",
    "# print(date1)\n",
    "# print(date2)\n",
    "# fetch 1 minute klines for the last day up until now\n",
    "klines = client.get_historical_klines(\"BTCUSDT\", Client.KLINE_INTERVAL_1MINUTE, date1,date2)\n",
    "#print(klines)\n",
    "\n",
    "\n",
    "frame = pd.DataFrame(klines)\n",
    "frame = frame.iloc[:,:6]\n",
    "frame.columns= [\"Time\",\"Open\",\"High\",\"Low\",\"Close\",\"Volume\"]\n",
    "#frame = frame[[\"Time\",\"Close\"]]\n",
    "frame = frame.set_index(\"Time\")\n",
    "frame.index = pd.to_datetime(frame.index,unit=\"ms\")\n",
    "frame.index = frame.index + timedelta(hours=2) #utc to local\n",
    "frame = frame.astype(float)\n",
    "print(frame)\n",
    "#print(frame)\n",
    "\n",
    "#[print(x) for x in frame.index if get_this_date in x]\n",
    "\n",
    "# for i in frame.index:\n",
    "#     if i == get_this_date:\n",
    "#         print ('date exist')\n",
    "\n",
    "# for kline in client.get_historical_klines_generator(\"BTCUSDT\", Client.KLINE_INTERVAL_1MINUTE, \"1 day ago UTC\"):\n",
    "#     print(kline)\n",
    "\n",
    "\n",
    "# order = client.create_test_order(\n",
    "#     symbol='BTCUSDT',\n",
    "#     side=SIDE_BUY,\n",
    "#     type=ORDER_TYPE_MARKET,\n",
    "#     quantity=0.0001,\n",
    "#     #timeInForce=TIME_IN_FORCE_GTC,\n",
    "#     #price=\"240077\"\n",
    "# )\n",
    "\n",
    "# get all open order\n",
    "# orders = client.get_open_orders(symbol='BTCUSDT')\n",
    "# orders = client.get_all_orders(symbol='BTCUSDT')\n",
    "\n",
    "#cancel order\n",
    "#result = client.cancel_order( symbol='BNBBTC', orderId='orderId')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset=\"BTCUSDT\"\n",
    "def getminutedata(symbol,interval, lookback):\n",
    "    frame = pd.DataFrame(client.get_historical_klines(symbol,interval,lookback))\n",
    "    frame = frame.iloc[:,:6]\n",
    "    frame.columns= [\"Time\",\"Open\",\"High\",\"Low\",\"Close\",\"Volume\"]\n",
    "    frame = frame.set_index(\"Time\")\n",
    "    frame.index = pd.to_datetime(frame.index,unit=\"ms\")\n",
    "    frame = frame.astype(float)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(plt.style.available)\n",
    "\n",
    "data = getminutedata(asset,\"1m\",\"12 July, 2022 20:00\")\n",
    "#sent = getSentiment() #RETURN DATAFRAMES    \n",
    "plt.figure(figsize=((12,6)))\n",
    "#plt.cla()\n",
    "ax1 = plt.subplot(121)\n",
    "plt.tick_params('x')\n",
    "plt.title(f\"Price for {asset}\")\n",
    "\n",
    "plt.plot(data.index,data.Close)\n",
    "\n",
    "ax2 = plt.subplot(122,label=\"Sentiment Score2\") #,sharex=ax1)\n",
    "# make these tick labels invisible\n",
    "plt.tick_params('x')   \n",
    "plt.title(\"Sentiment Score\")\n",
    "#plt.plot(sent)#sent.index,sent[\"Sentiment Score\"].values)\n",
    "\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "from binance import Client\n",
    "client = Client(API-KEY, API-SECRET,testnet=True)\n",
    "\n",
    "balance = client.get_asset_balance(asset='BTC')[\"free\"]\n",
    "btc_price = client.get_symbol_ticker(symbol=\"BTCUSDT\")[\"price\"]\n",
    "print(f\"Account Balance: {balance} BTC\")\n",
    "print(f\"Latest BTC Price: {btc_price} USDT\")\n",
    "\n",
    "order = client.create_test_order(\n",
    "    symbol='BNBBTC',\n",
    "    side=Client.SIDE_BUY,\n",
    "    type=Client.ORDER_TYPE_MARKET,\n",
    "    quantity=100)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sma\n",
    "#pip install bta-lib\n",
    "sma = btalib.sma(btc_df.close)\n",
    "print(sma.df)\n",
    "\n",
    "# create sma and attach as column to original df\n",
    "btc_df['sma'] = btalib.sma(btc_df.close, period=20).df\n",
    "print(btc_df.tail())\n",
    "\n",
    "import btalib\n",
    "import pandas as pd\n",
    "\n",
    "# load DataFrame\n",
    "btc_df = pd.read_csv('btc_bars3.csv', index_col=0)\n",
    "btc_df.set_index('date', inplace=True)\n",
    "btc_df.index = pd.to_datetime(btc_df.index, unit='ms')\n",
    "\n",
    "# calculate 20 moving average using Pandas\n",
    "btc_df['20sma'] = btc_df.close.rolling(20).mean()\n",
    "print(btc_df.tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heroku"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a heroku project\n",
    "2. heroku git:remote -a tweet-collector-sent    \n",
    "3. add procfile: worker: python3 sentiment/runner.py -k \"btc,eth,ada\" -i 5\n",
    "4. git add .\n",
    "5. git commit -am \"add proc\"\n",
    "6. git push heroku main\n",
    "\n",
    "### start heroku locally\n",
    "heroku local\n",
    "\n",
    "### run worker\n",
    "heroku run worker\n",
    "\n",
    "heroku run 'grep worker Procfile'\n",
    " heroku ps:scale worker=1  \n",
    " heroku logs --tail\n",
    "\n",
    "#Procfile\n",
    " worker: python sentiment/runner.py -k \"btc,eth,ada\" -i 5\n",
    "\n",
    "\n",
    " # no such file procfile\n",
    " heroku buildpacks:clear\n",
    "heroku buildpacks:set heroku/python\n",
    "\n",
    "es hat die ganze zeit nicht funktioniert, weil er den worker nicht gefunden hat\n",
    "Fix: Manueller deploy Ã¼ber die heroku dashboard. buildpacks und alles hat nicht funktioniert\n",
    "\n",
    "# Wiederhole dies\n",
    "git add .\n",
    "git commit -am \"\"\n",
    "git push heroku main\n",
    "\n",
    "\n",
    "### CLI COMMANDS [Link](https://devcenter.heroku.com/articles/dynos#ephemeral-filesystem)\n",
    "\n",
    "## Heroku Database posgres\n",
    "heroku pg:info -a tweet-collector-sent\n",
    "\n",
    "heroku pg:psql\n",
    "\n",
    "heroku pg:pull postgresql-infinite-07732 mylocaldb --app tweet-collector-sent\n",
    "PGUSER=aajwlkayambzsb PGPASSWORD=3755e1900108039b5d84737bb263d0344c83a0e824564ce0c03a9998b618d6b6 heroku pg:pull postgresql-infinite-07732 mylocaldb --app tweet-collector-sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backup\n",
    "## manual backup\n",
    "heroku pg:backups:capture --app tweet-collector-sent\n",
    "\n",
    "## check backup status\n",
    "heroku pg:backups --app tweet-collector-sent\n",
    "\n",
    "## Schedule Backup\n",
    "\n",
    "heroku pg:backups:schedule DATABASE_URL --at '00:00 \"Europe/Berlin\" --app tweet-collector-sent\n",
    "\n",
    "## unschedule\n",
    "heroku pg:backups:unschedule DATABASE_URL --app tweet-collector-sent\n",
    "\n",
    "## view schedules\n",
    "heroku pg:backups:schedules --app example-app\n",
    "\n",
    "## download via url\n",
    "heroku pg:backups:url b001 --app example-app\n",
    "\n",
    "## download via cli\n",
    "heroku pg:backups:download\n",
    "\n",
    "## restore\n",
    "curl -o latest.dump `heroku pg:backups public-url --app appname`\n",
    "createdb dbname\n",
    "pg_restore --verbose --clean --no-acl --no-owner -d dbname latest.dump "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing and Saving my Collected tweets from heroku. But where?\n",
    "## First Attempt: Github Module\n",
    "- Did not work. Could not access the file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install PyGithub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from github import Github\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\"/Users/marvinottersberg/Documents/GitHub/sentiment/.env\")\n",
    "\n",
    "# First create a Github instance:\n",
    "\n",
    "# using an access token\n",
    "GITHUB_ACCESS_TOKEN = os.getenv('GITHUB_ACCESS_TOKEN')\n",
    "github = Github(GITHUB_ACCESS_TOKEN)\n",
    "\n",
    "# Github Enterprise with custom hostname\n",
    "#g = Github(base_url=\"https://{hostname}/api/v3\", login_or_token=GITHUB_ACCESS_TOKEN)\n",
    "repository = github.get_user().get_repo('sentiment')\n",
    "\n",
    "# Then play with your Github objects:\n",
    "# for repo in github.get_user().get_repos():\n",
    "    #print(repo.name)\n",
    "\n",
    "    \n",
    "# path in the repository\n",
    "filename = 'files/file.json'\n",
    "json_dir = 'sentiment/Json/12-07-2022/' #blob/tweet_collector/\n",
    "for file in repository.get_contents(json_dir):\n",
    "    #print(file.decoded_content.decode())\n",
    "    print(file.content())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Attempt: Heroku Posgres DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Add Heroku Posgres to Heroku Dashboard or via cli:\n",
    "heroku addons:create heroku-postgresql:hobby-dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Credentials\n",
    "\n",
    "heroku pg:credentials DATABASE\n",
    "\n",
    "or:\n",
    "\n",
    "heroku pg:credentials:url \n",
    "\n",
    "heroku config | grep HEROKU_POSTGRESQL\n",
    "\n",
    "heroku config:set API_KEY=z2DVJYFC0LkyPfEpog1AmvOhw\n",
    "heroku config:set API_SECRET=H6swvZXxYFBu5IBlzBkxDvRDfxwzQR9E2vlw1rzDLvB08yDYTn\n",
    "heroku config:set ACCESS_SECRET=2xd7EaypEUoKV87iD3xnk7omUcbgq5PqnJWSBOS0U68sq\n",
    "heroku config:set ACCESS_TOKEN=1202179097314631680-mHAbH3RGDwI52bjINqJs9jotSRyyWT\n",
    "\n",
    "heroku config:set KUCOIN_API_KEY='62f38d4537a609000198c428'\n",
    "heroku config:set KUCOIN_SECRET='f7589be5-1db4-4ec7-95d3-843874b78759'\n",
    "heroku config:set KUCOIN_PASS='473qz97385qfozhqo3fhwqe8hf2ru7'\n",
    "heroku config:set KUCOIN_SUB_KEY='62f3af0141a5330001d1bfd5'\n",
    "heroku config:set KUCOIN_SUB_SECRET='dcaad6ce-7d9c-45ef-9705-1e6e53beb850'\n",
    "ei\n",
    "heroku config:set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connection info string:\n",
    "   \"dbname=d2vfhe1prooh9b host=ec2-52-30-159-47.eu-west-1.compute.amazonaws.com port=5432 user=aajwlkayambzsb password=7f40874d06611a27ca0bea79d3a215747efaf495a5038d29c15ab0a056df928a sslmode=require\"\n",
    "#### Connection URL:\n",
    "   postgres://aajwlkayambzsb:7f40874d06611a27ca0bea79d3a215747efaf495a5038d29c15ab0a056df928a@ec2-52-30-159-47.eu-west-1.compute.amazonaws.com:5432/d2vfhe1prooh9b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Password authentifaction failed\n",
    "ERROR MESSAGE: sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at \"ec2-52-30-159-47.eu-west-1.compute.amazonaws.com\" (52.30.159.47), port 5432 failed: FATAL:  password authentication failed for user \"aajwlkayambzsb\"\n",
    "\n",
    "### What worked: \n",
    "Using the DATABASE URL in create_engine instead of host, user,password...\n",
    "\n",
    "\n",
    "pg_dump --verbose -F c -Z 0 -U postgres -h localhost -p 5432 yourdbname > local.dump\n",
    "\n",
    "\n",
    "pg_ctl -D /usr/local/var/postgres -l /usr/local/var/postgres/server.log restart\n",
    "/usr/local/var/postgres is the location of the database storage area, and /usr/local/var/postgres/server.log is my log file for postgres. The last word restart is the operative word here. You can also use start to start the service.\n",
    "\n",
    "You can find the location of the database storage area by running \n",
    "\n",
    "    ps aux | grep postgres | grep -- -D\n",
    "\n",
    "pg_ctl -D /Library/PostgreSQL/14/data restart\n",
    "pg_ctl -D /usr/local/var/postgres/ restart\n",
    "\n",
    "    postgres           148   0.0  0.0 34670412    812   ??  Ss   10Jul22   0:03.99 /Library/PostgreSQL/14/bin/postmaster -D /Library/PostgreSQL/14/data\n",
    "\n",
    "### Possible Solution: sslmode needs to be required\n",
    "heroku config:set PGSSLMODE=require\n",
    "\n",
    "\n",
    "### postgres db file/dir not found\n",
    "initdb -D /usr/local/var/postgres/\n",
    "\n",
    "pg_ctl -D /usr/local/var/postgres/ -l logfile start\n",
    "\n",
    "\n",
    "### Heroku Workflow Problem:\n",
    "Manual deploy works and syncs with the code but just github push doesnt... or takes forever..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example Code \n",
    "Connecting in Python: [Link](https://devcenter.heroku.com/articles/connecting-heroku-postgres#connecting-in-python)\n",
    "\n",
    "To use PostgreSQL as your database in Python applications you must use the psycopg2 package.\n",
    "    $ pip install psycopg2-binary\n",
    "And use this package to connect to DATABASE_URL in your code.\n",
    "   \n",
    "    import os\n",
    "    import psycopg2\n",
    "\n",
    "    DATABASE_URL = os.environ['DATABASE_URL']\n",
    "\n",
    "    conn = psycopg2.connect(DATABASE_URL, sslmode='require')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Heroku DB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "#Config\n",
    "os.sys.path.insert(0,\"/Users/marvinottersberg/Documents/GitHub/sentiment/\")\n",
    "from config import ConfigDB\n",
    "newconf = ConfigDB()\n",
    "\n",
    "DATABASE_URL = newconf.DB_URL\n",
    "# Connect to your postgres DB\n",
    "conn = psycopg2.connect(DATABASE_URL)\n",
    "#conn = psycopg2.connect(DATABASE_URL, sslmode='require')\n",
    "cur = conn.cursor()\n",
    "\n",
    "#cur.execute(\"\"\"SELECT relname FROM pg_class WHERE relkind='r'\n",
    "#                AND relname !~ '^(pg_|sql_)';\"\"\") # \"rel\" is short for relation.\n",
    "\n",
    "# tables = [i[0] for i in cur.fetchall()] # A list() of tables\n",
    "# print(tables) # -> \"Tweet Data\"\n",
    "\n",
    "# cur.execute(\"select * from tweet_data\")\n",
    "# print(cur.fetchone())\n",
    "# Retrieve query results\n",
    "# records = cur.fetchall()\n",
    "\n",
    "# query2 = f\"delete from tweet_data where Tweet_Date < (current_date - Integer '1') \"\n",
    "# cur.execute(query2)\n",
    "#query3 = f\"delete from tweet_data where id = 1 \"\n",
    "query3 = (\"delete from tweet_data where id in (select id from tweet_data order by id asc limit 10);\")\n",
    "cur.execute(query3)\n",
    "conn.commit()\n",
    "cur.execute(\"select * from tweet_data\")\n",
    "records = cur.fetchall()\n",
    "print([i for i in records])\n",
    "# cur.execute(\"select count(*) from Tweet_data\")\n",
    "# results = cur.fetchone()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_sql_table(\"tweet_data\",DATABASE_URL)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump heroku database\n",
    "    \n",
    "\n",
    "        \n",
    "    def dump_clean_database(self):\n",
    "        conn = psycopg2.connect(conf.DB_URL,sslmode=\"require\")\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(\"Select exists(select from pg_tables where tablename='tweet_data')\")\n",
    "        if cur.fetchone() == True:\n",
    "            cur.execute(\"select count(*) from tweet__data\")\n",
    "            results = cur.fetchone()\n",
    "            if results > 9000:\n",
    "                query2 = f\"delete from tweet_data where Tweet_Date < (current_date - Integer '1') \"\n",
    "                cur.execute(query2)\n",
    "                query3 = f\"delete from tweet_data where id in (select id from tweet_data order by id asc limit 100);\"\n",
    "                cur.execute(query3)\n",
    "                conn.commit()\n",
    "                json_dir = 'sentiment/Logs/Json/'\n",
    "                date_dir = date.today().strftime('%d-%m-%Y')\n",
    "                final_dir = os.path.join(json_dir,date_dir)\n",
    "                if not os.path.exists(final_dir):\n",
    "                    os.mkdir(final_dir)\n",
    "                    print(f\"Created new Directory for {date_dir}\")\n",
    "                    logger.info(f\"Created new Directory for {date_dir}\")\n",
    "                json_file = os.path.join(final_dir,f\"{date_dir}_dbdump.json\")\n",
    "                df.to_json(json_file,orient=\"index\",indent=4) \n",
    "                \n",
    "\n",
    "                \n",
    "            else:\n",
    "                query = f\"select * from tweet_data where Tweet_Date < (current_date - Integer '1') order by id desc;\"\n",
    "                df = pd.read_sql(query,conn)\n",
    "                columns = {\"body\": \"Tweet\",\n",
    "                            \"keyword\": \"Keyword\",\n",
    "                            \"tweet_date\": \"Timestamp\",\n",
    "                            \"location\": \"Location\",\n",
    "                            \"verified_user\": \"User verified\",\n",
    "                            \"followers\": \"Followers\",\n",
    "                            \"user_since\": \"User created\",\n",
    "                            \"sentiment\": \"Sentiment Score\",\n",
    "                            \"sentiment_meaning\": \"Null\"}\n",
    "                df = df.drop(columns=[\"sentiment_meaning\"])\n",
    "                df = df.rename(columns=columns)\n",
    "                df[\"Timestamp\"] = df[\"Timestamp\"] + timedelta(hours=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_sentiment = self.sentiment_model.polarity_scores(text).get(\"compound\")\n",
    "if tweet_sentiment > 0.1:\n",
    "    tweet_sent_meaning = \"Positive\"\n",
    "elif tweet_sentiment< -0.1:\n",
    "    tweet_sent_meaning =  \"Negative\"\n",
    "else:\n",
    "    tweet_sent_meaning = \"Neutral\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trading Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Buy coin after model recommendations\n",
    "\n",
    "2. Sell after X% of value increase to take profits or X% of decrease to stop further loss\n",
    "\n",
    "3. If nothing happens sell (after X days) or hold "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uptrend erkennbar -> kaufen\n",
    "downtrend erkennbar -> verkaufen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import os\n",
    "import signal\n",
    "from regex import W\n",
    "import streamlit as st\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "import logging\n",
    "from datetime import date, time, timedelta,datetime\n",
    "from logging.handlers import RotatingFileHandler\n",
    "import subprocess\n",
    "import shlex\n",
    "import psutil\n",
    "from time import sleep\n",
    "from streamlit_autorefresh import st_autorefresh\n",
    "from dateutil import tz\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "DB_URL =\"postgresql://gmsfgzvfgjiyjf:3755e1900108039b5d84737bb263d0344c83a0e824564ce0c03a9998b618d6b6@ec2-54-75-26-218.eu-west-1.compute.amazonaws.com:5432/d6codjvmqs1fmm\"\n",
    "\n",
    "\n",
    "\n",
    "def get_Heroku_DB(limit=10000):\n",
    "    conn = psycopg2.connect(DB_URL, sslmode=\"require\")\n",
    "    query = f\"select * from tweet_data where Tweet_Date < (current_date - Integer '1') order by id desc;\"\n",
    "    df = pd.read_sql(query, conn)\n",
    "    columns = {\"body\": \"Tweet\",\n",
    "                \"keyword\": \"Keyword\",\n",
    "                \"tweet_date\": \"Timestamp\",\n",
    "                \"location\": \"Location\",\n",
    "                \"verified_user\": \"User verified\",\n",
    "                \"followers\": \"Followers\",\n",
    "                \"user_since\": \"User created\",\n",
    "                \"sentiment\": \"Sentiment Score\",\n",
    "                \"sentiment_meaning\": \"Null\"}\n",
    "    df = df.drop(columns=[\"sentiment_meaning\"])\n",
    "    df = df.rename(columns=columns)\n",
    "    # Needed because the conversion to local time does not work - database is in utc timezone\n",
    "    df[\"Timestamp\"] = df[\"Timestamp\"] \n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "df = get_Heroku_DB()\n",
    "print(df.tail(5))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_sent_meaning(sent_list):\n",
    "    sent_meaning_list = []\n",
    "    for num in sent_list:\n",
    "        sent_meaning_list.append(conv_sent_score_to_meaning(num))\n",
    "    mean_avg = sum(sent_list) / len(sent_list)\n",
    "    return mean_avg, sent_meaning_list\n",
    "\n",
    "def conv_sent_score_to_meaning(num):\n",
    "    if num > 0.2 and num < 0.6:\n",
    "        return(\"Positive\")\n",
    "    elif num > 0.6:\n",
    "        return(\"Very Positive\")\n",
    "    elif num < - 0.2 and num > -0.6:\n",
    "        return(\"Negative\")\n",
    "    elif num < - 0.6 :\n",
    "        return(\"Very Negative\")\n",
    "    else:\n",
    "        return(\"Neutral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Tweet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/dontbesentimental/lib/python3.9/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Tweet'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/marvinottersberg/Documents/GitHub/moervs-python-snippets/Moervs-Code-Collection.ipynb Cell 42\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/marvinottersberg/Documents/GitHub/moervs-python-snippets/Moervs-Code-Collection.ipynb#X56sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39msort_values(by\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mCount\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mSentiment\u001b[39m\u001b[39m\"\u001b[39m],ascending\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/marvinottersberg/Documents/GitHub/moervs-python-snippets/Moervs-Code-Collection.ipynb#X56sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m df\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/marvinottersberg/Documents/GitHub/moervs-python-snippets/Moervs-Code-Collection.ipynb#X56sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m df_freq \u001b[39m=\u001b[39m getFrequencyDictForText(df)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/marvinottersberg/Documents/GitHub/moervs-python-snippets/Moervs-Code-Collection.ipynb#X56sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m df_freq\n",
      "\u001b[1;32m/Users/marvinottersberg/Documents/GitHub/moervs-python-snippets/Moervs-Code-Collection.ipynb Cell 42\u001b[0m in \u001b[0;36mgetFrequencyDictForText\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/marvinottersberg/Documents/GitHub/moervs-python-snippets/Moervs-Code-Collection.ipynb#X56sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetFrequencyDictForText\u001b[39m(df):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/marvinottersberg/Documents/GitHub/moervs-python-snippets/Moervs-Code-Collection.ipynb#X56sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     all_words \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([tweets \u001b[39mfor\u001b[39;00m tweets \u001b[39min\u001b[39;00m df[\u001b[39m'\u001b[39;49m\u001b[39mTweet\u001b[39;49m\u001b[39m'\u001b[39;49m]])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/marvinottersberg/Documents/GitHub/moervs-python-snippets/Moervs-Code-Collection.ipynb#X56sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     words \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39m(all_words\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/marvinottersberg/Documents/GitHub/moervs-python-snippets/Moervs-Code-Collection.ipynb#X56sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m#set_words = [i for i in words if i not in my_stopwords] #if not bool(re.search('\\d|_|\\$', i)\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dontbesentimental/lib/python3.9/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3506\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dontbesentimental/lib/python3.9/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Tweet'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import multidict\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "my_stopwords={\"amp\"}\n",
    "sentiment_model = SentimentIntensityAnalyzer()\n",
    "\n",
    "def getFrequencyDictForText(df):\n",
    "    all_words = ' '.join([tweets for tweets in df['Tweet']])\n",
    "    words = list(set(all_words.split(\" \")))\n",
    "    #set_words = [i for i in words if i not in my_stopwords] #if not bool(re.search('\\d|_|\\$', i)\n",
    "    cleaned_words = [x for x in words if not bool(re.search('\\d|_|\\$|\\amp', x))]\n",
    "    cleaned_words = [re.sub(r\"\\.|\\!|\\,|\\(|\\)|\\-|\\?|\\;|\\\\|\\'\",\"\",x) for x in cleaned_words]\n",
    "    fullTermsDict = multidict.MultiDict()\n",
    "    tmpDict = {}\n",
    "    # making dict for counting frequencies\n",
    "    for text in cleaned_words:\n",
    "        if re.match(\"a|the|an|the|to|in|for|of|or|by|with|is|on|that|be\", text):\n",
    "            continue\n",
    "        val = tmpDict.get(text, 0)\n",
    "        tmpDict[text.lower()] = val + 1\n",
    "    for key in tmpDict:\n",
    "        fullTermsDict.add(key, tmpDict[key])\n",
    "    del fullTermsDict[\"\"]\n",
    "    df = pd.DataFrame.from_dict(fullTermsDict,orient=\"index\",columns=[\"Count\"])\n",
    "    sent_list = [sentiment_model.polarity_scores(words).get(\"compound\") for words in df.index]\n",
    "    mean_avg,sent_meaning_list = get_sent_meaning(sent_list)\n",
    "    df[\"Sentiment\"] = sent_meaning_list\n",
    "    \n",
    "    df = df.sort_values(by=[\"Count\",\"Sentiment\"],ascending=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "df_freq = getFrequencyDictForText(df)\n",
    "df_freq\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment with FLair Model\n",
    "from flair.models import TextClassifier,SequenceTagger\n",
    "from flair.data import Sentence\n",
    "sia = TextClassifier.load('en-sentiment')\n",
    "def flair_prediction(x):\n",
    "    sentence = Sentence(x)\n",
    "    sia.predict(sentence)\n",
    "    print(sentence.labels)\n",
    "    score = sentence.labels[0]\n",
    "    if \"POSITIVE\" in str(score):\n",
    "        return \"pos\"\n",
    "    elif \"NEGATIVE\" in str(score):\n",
    "        return \"neg\"\n",
    "    else:\n",
    "        return \"neu\"\n",
    "df_sent_flair = df.head(5)\n",
    "\n",
    "df_sent_flair = df[\"Tweet\"].apply(flair_prediction)\n",
    "df_sent_flair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweets cleanen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "def cleanTweets(text):\n",
    "    \"\"\"Removes unnecessary information from tweets\n",
    "    Args:\n",
    "        text (str): input text\n",
    "    Returns:\n",
    "        str: cleaned text\n",
    "    \"\"\"\n",
    "    text = re.sub(r'@[A-Za-z0-9]+',\"\",text,flags=re.IGNORECASE) #removes @mentions / r tells python that it is a raw stream (regex)\n",
    "    text = re.sub(r'#[A-Za-z0-9]+',\"\",text, flags=re.IGNORECASE) #removes # \n",
    "    text = re.sub(r':',\"\",text,) #removes ':'\n",
    "    #text = demoji.replace(text, \"\") #removes emojis\n",
    "    text = re.sub(r'\\n+',\"\",text) #removes \\n \n",
    "    text = re.sub(r'&amp;*|&amp|amp',\"\",text) #removes &amp;\n",
    "    text = re.sub(r'RT[\\s]+',\"\",text) #removes retweets\n",
    "    text = re.sub(r'_*|\\+*',\"\",text)\n",
    "    text = re.sub(r\"\\.|\\!|\\,|\\(|\\)|\\-|\\?|\\;|\\\\|\\'\",\"\",text) #removes other symbols\n",
    "    #text = re.sub(r'https?:\\/\\/\\S+',\"\",text) #removes hyperlink, the '?' matches 0 or 1 reps of the preceding 's'\n",
    "    text = re.sub(r\"http\\S+\",\"\",text,flags=re.IGNORECASE)\n",
    "    return text\n",
    "\n",
    "\n",
    "text = \"_boii &amp people think is high now wait till itâs $20k + by the end of this week $50k+ by end of 734982 this month  yâall should follow  he's    a super underrated !bitcoiner iâve been :following her tweets  and tips seriously  iâve  been doing really great! #btc #ada\"\n",
    "\n",
    "newtext = cleanTweets(text)\n",
    "#print(newtext)\n",
    "\n",
    "words = newtext.split(\" \")\n",
    "#print(words)\n",
    "cleaned_words = [x for x in words if not bool(re.search('^[0-9]+$|^$', x))] #removes empty string (\"\") and numbers that stand alone like 981238 but leaves numbers with symbols or letters like $50k\n",
    "#print(cleaned_words)\n",
    "#cleaned_words = [re.sub(r'#[AC-Zac-z0-9]*',\"\",x, flags=re.IGNORECASE) for x in #cleaned_words if not bool(re.search('#b',x))]\n",
    "#print(cleaned_words)\n",
    "text = \" \".join(cleaned_words)\n",
    "sent = SentimentIntensityAnalyzer().polarity_scores(text).get(\"compound\")\n",
    "test2 = SentimentIntensityAnalyzer().polarity_scores(\"i am still bullish\").get(\"compound\")\n",
    "\n",
    "print(test2) \n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_duplicates(tweet_list):\n",
    "    \"\"\"Check and Clean Tweet List for Duplicates\n",
    "\n",
    "    Args:\n",
    "        tweet_list (list): List of Tweet Metric: Tweet, Location, User created, etc..\n",
    "\n",
    "    Returns:\n",
    "        list: tweet metrics\n",
    "    \"\"\"\n",
    "    cols = [\"Tweet\", \"Keyword\", \"Time\", \"Location\",\"Verified\",\"Followers\",\"User created\", \"Sentiment Score\"]\n",
    "    df = pd.DataFrame(tweet_list,columns=cols)\n",
    "    duplicates = list(df.index[df.duplicated(subset=[\"Tweet\"],keep=False)])\n",
    "    df.drop(labels=duplicates,inplace=True)\n",
    "    logger.info(f\"Deleted {len(duplicates)} duplicates.\")\n",
    "    print(f\"Deleted {len(duplicates)} duplicates.\")\n",
    "    return df.values.tolist()\n",
    "\n",
    "\n",
    "\"\"\" Deprecated: Will check duplicates afterwards\n",
    "Adding tweets to a list so they can be checked for duplicates\n",
    "self.tweet_list.append(metrics)\n",
    "\n",
    "logger.info(f\"Collected Tweets: {len(self.tweet_list)}\")\n",
    "print(f\"Collected Tweets: {len(self.tweet_list)}\")\n",
    "There are around 40 Tweets collected in a minute\n",
    "These 40 Tweets will be checked for duplicates and if there are any delete them.\n",
    "if len(self.tweet_list) >=40:\n",
    "    cleaned_list = check_duplicates(self.tweet_list)\n",
    "    for items in cleaned_list:\n",
    "        tweet = Tweet(body = items[0],\n",
    "                    keyword = items[1],\n",
    "                    tweet_date = items[2],\n",
    "                    location = items[3],\n",
    "                    verified_user = items[4],\n",
    "                    followers = items[5],\n",
    "                    user_since = items[6],\n",
    "                    sentiment = items[7]) \n",
    "                \"\"\"\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Textblob vs vader\n",
    "from textblob import TextBlob\n",
    "text = \"i am still bullish\"\n",
    "print(TextBlob(text).sentiment.subjectivity)\n",
    "print(TextBlob(text).sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, time\n",
    "from dateutil import tz\n",
    "\n",
    "def datetime_from_utc_to_local(utc_datetime):\n",
    "    # Get local timezone\n",
    "    local_zone = tz.tzlocal()\n",
    "    # Convert UTC to local time zone\n",
    "    local_time = datetime.now(tz.gettz())\n",
    "    print(local_time)\n",
    "    return local_time\n",
    "\n",
    "local = datetime_from_utc_to_local(datetime.utcnow())\n",
    "print(local)\n",
    "\n",
    "datetime.now().strftime(\"%Y-%m-%d %H:%M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL ALchemy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Init DB Connection\n",
    "#Format: dialect+driver://username:password@host:port/database -> 'postgresql://scott:tiger@localhost/mydatabase'\n",
    "\n",
    "# user1 = sess.query(Tweet).all()#.all()#filter_by(id=1).first()\n",
    "# first100 = sess.query(Tweet).limit(100).all()\n",
    "# if len(user1) > 100:\n",
    "#     sess.delete(first100)\n",
    "# print(first100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marvinottersberg/opt/anaconda3/envs/dontbesentimental/lib/python3.9/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>body</th>\n",
       "      <th>keyword</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>location</th>\n",
       "      <th>verified_user</th>\n",
       "      <th>followers</th>\n",
       "      <th>user_since</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138083</td>\n",
       "      <td>gm and #short #btc now</td>\n",
       "      <td>#btc</td>\n",
       "      <td>2022-08-14 12:20:34</td>\n",
       "      <td>HÃ  Ná»i, Viá»t Nam</td>\n",
       "      <td>False</td>\n",
       "      <td>1178</td>\n",
       "      <td>2020-02-27 06:34:23</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>138082</td>\n",
       "      <td>ernst #bitcoin#beafÃ»ckingrebel#nokyc#fÃ»ckwefwe...</td>\n",
       "      <td>bitcoin</td>\n",
       "      <td>2022-08-14 12:20:27</td>\n",
       "      <td>â¡ï¸ lassmiranda21@getalby.com</td>\n",
       "      <td>False</td>\n",
       "      <td>879</td>\n",
       "      <td>2021-09-19 12:12:13</td>\n",
       "      <td>0.7351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>138081</td>\n",
       "      <td>top #crypto pairs to watch this week $ada $btc...</td>\n",
       "      <td>$btc</td>\n",
       "      <td>2022-08-14 12:20:27</td>\n",
       "      <td>Tel Aviv</td>\n",
       "      <td>False</td>\n",
       "      <td>7923</td>\n",
       "      <td>2011-07-20 10:59:20</td>\n",
       "      <td>0.2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                               body  keyword  \\\n",
       "0  138083                             gm and #short #btc now     #btc   \n",
       "1  138082  ernst #bitcoin#beafÃ»ckingrebel#nokyc#fÃ»ckwefwe...  bitcoin   \n",
       "2  138081  top #crypto pairs to watch this week $ada $btc...     $btc   \n",
       "\n",
       "           tweet_date                      location  verified_user  followers  \\\n",
       "0 2022-08-14 12:20:34              HÃ  Ná»i, Viá»t Nam          False       1178   \n",
       "1 2022-08-14 12:20:27  â¡ï¸ lassmiranda21@getalby.com          False        879   \n",
       "2 2022-08-14 12:20:27                      Tel Aviv          False       7923   \n",
       "\n",
       "           user_since  sentiment  \n",
       "0 2020-02-27 06:34:23     0.0000  \n",
       "1 2021-09-19 12:12:13     0.7351  \n",
       "2 2011-07-20 10:59:20     0.2023  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "\n",
    "DATABASE_URL = \"postgresql://wjhgxflbnaygwb:65c900f1fb2e477ae1fa161e543db8b81d613fe7b8b6fbdb1f2e370bd07a6017@ec2-54-228-218-84.eu-west-1.compute.amazonaws.com:5432/db1m9hb4f699st\"\n",
    "\n",
    "conn = psycopg2.connect(DATABASE_URL, sslmode='require')\n",
    "\n",
    "query = f\"select * from tweet_data order by id desc limit 3;\"\n",
    "\n",
    "df = pd.read_sql(query, conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../sentiment/sentiment/test_dataframe.csv\")#names=[\"id\",\"body\",\"keyword\",\"tweet_date\",\"location\",\"verified_user\",\"followers\",\"user_since\",\"sentiment\"])\n",
    "#print(df.iloc[2])\n",
    "#df = pd.read_excel(\"../sentiment/sentiment/Logs/Excel/test_dataframe.xlsx\",names=[\"id\",\"body\",\"keyword\",\"tweet_date\",\"location\",\"verified_user\",\"followers\",\"user_since\",\"sentiment\"],engine=\"openpyxl\")\n",
    "#print(len(df))\n",
    "# duplicates = list(df.index[df.duplicated(subset=[\"body\"])])\n",
    "# print(duplicates)\n",
    "# df.drop(labels=duplicates,inplace=True)\n",
    "# print(len(df))\n",
    "# # print(len(df))\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time period 1: 1st August - 12th August\n",
      "30731 duplicates in 100000 tweets from 20113 users.\n",
      "\n",
      "time period: 20th August - 27th August\n",
      "26604 duplicates in 100000 tweets from 17690 users.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "path=\"/Users/marvinottersberg/Downloads/dataclips_devnvyctdpamubfvwczkygyrfovm.csv\"\n",
    "path2 = \"/Users/marvinottersberg/Downloads/dataclips_eynemvxjyggbjagnromjorwuxgbh.csv\"\n",
    "df = pd.read_csv(path)\n",
    "df2 = pd.read_csv(path2)\n",
    "users=len(df[\"user_since\"].unique())\n",
    "users2 =len(df2[\"user_since\"].unique())\n",
    "first_date = df2.tail(1)[\"tweet_date\"]\n",
    "second_date = df2.head(1)[\"tweet_date\"]\n",
    "\n",
    "duplicates = list(df.index[df.duplicated(subset=[\"body\"])])\n",
    "duplicates2 = list(df2.index[df2.duplicated(subset=[\"body\"])])\n",
    "perc = len(duplicates) / len(df) * 100\n",
    "perc2 = len(duplicates2) / len(df2) * 100\n",
    "userperc = users / len(df) *100\n",
    "userperc2 = users2 / len(df2) *100\n",
    "print(\"Time period 1: 1st August - 12th August\")\n",
    "print(f\"{len(duplicates2)} duplicates in {len(df2)} tweets from {users2} users.\")\n",
    "#print(f\"That means: {perc2}% duplicates and only {int(userperc2)}% unique users\")\n",
    "print(\"\")\n",
    "print(f\"time period: 20th August - 27th August\")\n",
    "print(f\"{len(duplicates)} duplicates in {len(df)} tweets from {users} users.\")\n",
    "#print(f\"That means: {perc}% duplicates and only {int(userperc)}% unique users\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime \n",
    "tweet_list = [['$btc 1% = $snx 3% upto 5%assuming $btc pulls a move to $28k$32k id assume $snx to pull a 25x35x', '$btc', datetime.datetime(2022, 8, 2, 11, 40, 41, tzinfo=datetime.timezone.utc), None, False, 41801, datetime.datetime(2018, 1, 1, 16, 39, 42, tzinfo=datetime.timezone.utc), 0.0],['$btc 1% = $snx 3% upto 5%assuming $btc pulls a move to $28k$32k id assume $snx to pull a 25x35x', '$btc', datetime.datetime(2022, 8, 2, 11, 40, 41, tzinfo=datetime.timezone.utc), None, False, 41801, datetime.datetime(2018, 1, 1, 16, 39, 42, tzinfo=datetime.timezone.utc), 0.0],['safadsffasdfsfnx 3% upto 5%assuming $btc pulls a move to $28k$32k id assume $snx to pull a 25x35x', '$btc', datetime.datetime(2022, 8, 2, 11, 40, 41, tzinfo=datetime.timezone.utc), None, False, 41801, datetime.datetime(2018, 1, 1, 16, 39, 42, tzinfo=datetime.timezone.utc), 0.0]]\n",
    "\n",
    "cols = [\"Tweet\", \"Keyword\", \"Time\", \"Location\",\"Verified\",\"Followers\",\"User created\", \"Sentiment Score\"]\n",
    "df = pd.DataFrame(tweet_list,columns=cols)\n",
    "\n",
    "duplicates = list(df.index[df.duplicated(subset=[\"Tweet\"],keep=False)])\n",
    "#df.drop(labels=duplicates,inplace=True)\n",
    "new_list = df.values.tolist()\n",
    "#print(new_list[0][0])\n",
    "\n",
    "for items in new_list:\n",
    "    print(items[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keyowrds\n",
    "        # i =0 \n",
    "        # for val in list(self.keyword_dict.items()):\n",
    "            # This looks for keyword like \"btc\" or \"ada\" -> results in lots of unrelated tweets \n",
    "            # if re.search(rf\"\\b{key}\\b\", body, re.IGNORECASE):  \n",
    "            #     return key, list(self.keyword_dict.keys())[i]\n",
    "            # for keyword in val:\n",
    "            #     if keyword.lower() in body:\n",
    "            #         return keyword, list(self.keyword_dict.keys())[i]\n",
    "            # i+=1\n",
    "        # if any([key in body for key in self.keyword_lst]):\n",
    "        #     print(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytz\n",
    "from datetime import datetime \n",
    "berlin_timezone = pytz.timezone(\"Europe/Berlin\")\n",
    "tzi = datetime.now(berlin_timezone).strftime(\"%Y-%m-%d %H:%M:%S %Z:%z\")\n",
    "print(tzi)\n",
    "\n",
    "\n",
    "#Adding 2 hours to utc time to match local time (Europe/Berlin)\n",
    "tz = pytz.timezone(\"Europe/Berlin\")\n",
    "\n",
    "status_created_at = status.created_at.astimezone(tz)\n",
    "user_created_at = status.user.created_at.astimezone(tz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive: 0.4019\n",
      "Negative: -0.3412\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "#text = TextBlob(\"Just came across this pretty good CNBC piece on SpaceX & Starship\")\n",
    "#text = TextBlob(\"Ich kaufe niemals Bitcoin\")\n",
    "#print(f\"TextBlob: {text.sentiment.polarity}\")\n",
    "text = \"#Bitcoin is a smart investment.\"\n",
    "textneg = \"#Bitcoin is not a good investment.\"\n",
    "\n",
    "\n",
    "vader = SentimentIntensityAnalyzer().polarity_scores(text).get(\"compound\")\n",
    "vaderneg = SentimentIntensityAnalyzer().polarity_scores(textneg).get(\"compound\")\n",
    "print(f\"Positive: {vader}\")\n",
    "print(f\"Negative: {vaderneg}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you have costly operations you need to perform on a dataframe, (e.g. text preprocessing), you can split the operation into multiple cores to decrease the running time:\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# how many cores do you have?\n",
    "NUM_CORES=8\n",
    "\n",
    "# replace load_large_dataframe() with your dataframe\n",
    "df = load_large_dataframe()\n",
    "\n",
    "# split the dataframe into chunks, depending on hoe many cores you have\n",
    "df_chunks = np.array_split(df ,NUM_CORES)\n",
    "\n",
    "# this is a function that takes one dataframe chunk and returns\n",
    "# the processed chunk (for example, adding processed columns)\n",
    "def process_df(input_df):\n",
    "    # copy the dataframe to prevent mutation in place\n",
    "    output_df = input_df.copy()\n",
    "\n",
    "    # apply a function to every row *in this chunk*\n",
    "      output_df['new_column'] = output_df.apply(some_function, axis=1)    \n",
    "\n",
    "    return output_df\n",
    "\n",
    "with multiprocessing.Pool(NUM_CORES) as pool:\n",
    "    # process each chunk in a separate core and merge the results\n",
    "    full_output_df = pd.concat(pool.map(process_df, df_chunks), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "l = [[1, 2, 3], [1, None, 4], [2, 1, 3], [1, 2, 2]]\n",
    "df = pd.DataFrame(l, columns=[\"a\", \"b\", \"c\"])\n",
    "#df\n",
    "\n",
    "df.groupby(by=[\"b\"], dropna=True).sum()\n",
    "print(df.to_string())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conda env create -f environment.yml\n",
    "conda activate dontbesentimental\n",
    "\n",
    "Change settings.json to (cmd + shift + P -> Preference: Open Workspace Settings (JSON))\n",
    "```\n",
    "{\n",
    "    \"python.defaultInterpreterPath\": \"/Users/marvinottersberg/opt/anaconda3/envs/dontbesentimental/bin/python3.9\",\n",
    "    \"python.terminal.activateEnvironment\": true\n",
    "}\n",
    "```\n",
    "-> cmd + shift + p -> Terminal: Create New Terminal (at active Workspace)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -U vectorbt\n",
    "#%pip install yfinance\n",
    "\n",
    "import vectorbt as vbt\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from vectorbt.base.reshape_fns import broadcast_to\n",
    "# start_d = '2022-08-01 UTC'\n",
    "# end_d = '2022-08-09 UTC'\n",
    "price = vbt.YFData.download('BTC-USD').get('Close')\n",
    "#data = yf.download(\"BTC-USD\",period=\"5d\",interval=\"60m\").get(\"Close\")\n",
    "data = vbt.YFData.download(\"BTC-USD\",period=\"5d\",interval=\"60m\").get(\"Close\")\n",
    "#print(data.shape[0])\n",
    "# pf = vbt.Portfolio.from_holding(price, init_cash=100)\n",
    "# pf.total_profit()\n",
    "# print(data)\n",
    "\n",
    "#buy whenever 10sma crosses above 50sma and sell when opoosite\n",
    "fast_ma = vbt.MA.run(price, 10)\n",
    "slow_ma = vbt.MA.run(price, 50)\n",
    "entries = fast_ma.ma_crossed_above(slow_ma)\n",
    "# exits = fast_ma.ma_crossed_below(slow_ma)\n",
    "# print(\"Entries\")\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"resample_btc_df.csv\")\n",
    "df_exit = df.copy()\n",
    "df['Signal'] = (df['Signal'] ==\"BUY\").astype(bool)\n",
    "df_exit['Signal'] = (df_exit['Signal'] ==\"SELL\").astype(bool)\n",
    "df.index = pd.to_datetime(df[\"Timestamp\"],utc=True)\n",
    "df = df[\"Signal\"].sort_index(ascending=True)\n",
    "df_exit.index = pd.to_datetime(df_exit[\"Timestamp\"],utc=True)\n",
    "df_exit = df_exit[\"Signal\"].sort_index(ascending=True)\n",
    "df.shape[0]\n",
    "#df_exit.shape[0]\n",
    "\n",
    "s_entry = pd.concat([data.copy(),df],axis=1).drop(columns=[\"Close\"]).squeeze().fillna(False)\n",
    "s_exit = pd.concat([data.copy(),df_exit],axis=1).drop(columns=[\"Close\"]).squeeze().fillna(False)\n",
    "\n",
    "# print(s_entry)\n",
    "# print(s_exit)\n",
    "# print(data)\n",
    "#print(data.eq(s_entry))\n",
    "\n",
    "\n",
    "#pf = vbt.Portfolio.from_signals(price, entries, exits, init_cash=100)\n",
    "# pf = vbt.Portfolio.from_signals(data, s_entry, s_exit, init_cash=100)\n",
    "# print(\"Total Profit\")\n",
    "# print(pf.total_profit())\n",
    "\n",
    "# print(\"STATS\")\n",
    "# print(pf.stats())\n",
    "\n",
    "\n",
    "# vbt.Portfolio.from_orders(\n",
    "#     data, \n",
    "#     size=entries.astype(int) - exits.astype(int), \n",
    "#     size_type=\"value\"\n",
    "# ).final_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ta-lib\n",
    "from numba import njit\n",
    "from vectorbtpro.portfolio import nb as pf_nb, enums as pf_enums\n",
    "\n",
    "@njit\n",
    "def pipeline_1_nb(close, entries, exits, init_cash=100):\n",
    "    account_state = pf_enums.AccountState(  \n",
    "        cash=float(init_cash),\n",
    "        position=0.0,\n",
    "        debt=0.0,\n",
    "        free_cash=float(init_cash)\n",
    "    )\n",
    "    for i in range(close.shape[0]):\n",
    "        if entries[i]:\n",
    "            account_state, _ = pf_nb.buy_nb(  \n",
    "                account_state=account_state,\n",
    "                size=1 / close[i],\n",
    "                price=close[i]\n",
    "            )\n",
    "        if exits[i]:\n",
    "            account_state, _ = pf_nb.sell_nb(\n",
    "                account_state=account_state,\n",
    "                size=1 / close[i],\n",
    "                price=close[i]\n",
    "            )\n",
    "    return account_state.cash + account_state.position * close[-1]  \n",
    "\n",
    "data = vbt.YFData.download(\"BTC-USD\", end=\"2022-01-01\")\n",
    "sma_50 = vbt.talib(\"SMA\").run(data.get(\"Close\"), 50)\n",
    "sma_200 = vbt.talib(\"SMA\").run(data.get(\"Close\"), 200)\n",
    "entries = sma_50.real_crossed_above(sma_200)\n",
    "exits = sma_50.real_crossed_below(sma_200)\n",
    "\n",
    "pipeline_1_nb(\n",
    "    data.get(\"Close\").values, \n",
    "    entries.values, \n",
    "    exits.values\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streamlit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOCAL STREAMLIT FILE\n",
    "\n",
    "import signal\n",
    "from regex import W\n",
    "import streamlit as st\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, logging\n",
    "from datetime import date, time \n",
    "import subprocess, shlex, psutil\n",
    "from time import sleep\n",
    "from streamlit_autorefresh import st_autorefresh \n",
    "\n",
    "from streamlit_data import show_wordCloud,sent_meaning\n",
    "\n",
    "##PAGE SETUP\n",
    "logger = logging.getLogger(__name__)\n",
    "st.set_page_config(\n",
    "    page_title=\"Sentiment\", \n",
    "    layout=\"wide\", \n",
    "    )\n",
    "st.subheader(f\"Twitter Sentiment-Streaming for {date.today().strftime('%d-%m-%Y')}\")\n",
    "\n",
    "# For local setup\n",
    "def get_json_data():\n",
    "    \"\"\"Read Tweet Data for every Coin from Json File\n",
    "\n",
    "    Returns:\n",
    "        dataframes: dict\n",
    "    \"\"\"\n",
    "    dir = \"Json/\" + date.today().strftime('%d-%m-%Y')\n",
    "    dataframes = {}\n",
    "    if os.path.exists(dir):\n",
    "        for filename in os.listdir(dir):\n",
    "            file_path = os.path.join(dir, filename)\n",
    "            if os.path.isfile(file_path):\n",
    "                df = pd.read_json(file_path, orient=\"index\")\n",
    "                dataframes.update({filename: df})\n",
    "        return dataframes\n",
    "\n",
    "def start_local_process(coin_selection, refresh_rate):\n",
    "    command = shlex.split(\n",
    "        f\"python3 runner.py -k \\\"{coin_selection}\\\" -i \\\"{refresh_rate}\\\"\")\n",
    "    process = subprocess.Popen(\n",
    "        command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    return process\n",
    "\n",
    "def find_pid():\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    for proc in psutil.process_iter():\n",
    "        try:\n",
    "            pinfo = proc.as_dict(attrs=['pid', 'name', 'cmdline'])\n",
    "            if \"runner\" in str(pinfo[\"cmdline\"]):\n",
    "                logger.info(f\"Process {pinfo} running...\")\n",
    "                return pinfo[\"pid\"]\n",
    "            else:\n",
    "                continue\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "\n",
    "\n",
    "#Wordcloud for all Coins\n",
    "def show_data():\n",
    "    try:\n",
    "        i=0\n",
    "        cols= st.columns(len(dataframes.keys()))\n",
    "        for key, df in dataframes.items():\n",
    "            with cols[i]:\n",
    "                with st.expander(key[:-5].upper(),expanded=True):\n",
    "                    sent_avg, sent_avg_eval = sent_meaning(df[\"Sentiment Score\"])\n",
    "                    st.metric(\"Sentiment is:\",sent_avg_eval, f\"{sent_avg:5f}\")\n",
    "                    show_wordCloud(df)\n",
    "            i+=1\n",
    "    except:\n",
    "        logger.info(f\"No Data for {date.today().strftime('%d-%m-%Y')}\")\n",
    "        st.write(f\"No Data for {date.today().strftime('%d-%m-%Y')}\")\n",
    "\n",
    "#Sidebar\n",
    "st.sidebar.subheader(\"Mission Control\")\n",
    "coin_selection = st.sidebar.multiselect(\"What Coins do you want to listen to?\",[\"btc\",\"eth\",\"ada\",\"bnb\",\"xrp\"],default=\"btc\")\n",
    "refresh_rate = st.sidebar.number_input(\"Refresh Interval\",min_value=0.5,max_value=120.0,value=0.5,step=0.5,help=\"This refreshes the Page and reads the Data in given Interval.\\nValue in Min.\",format=\"%f\") #the page should also be refreshed in that rate\n",
    "\n",
    "#Starting & Stopping the Process\n",
    "process_status_text = f'<h3 style=\"color:Orange;\">OFFLINE</h3>'\n",
    "if find_pid() is not None:\n",
    "    process_status_text = f'<h3 style=\"color:Green;\">RUNNING</h3>'\n",
    "    btn_stop_runner = st.sidebar.button(\"Stop Listening\")\n",
    "    if btn_stop_runner:\n",
    "        pid = find_pid()\n",
    "        print(f\"Killed Process with PID:{find_pid()}\")\n",
    "        subprocess.os.kill(pid,signal.SIGTERM)\n",
    "else:\n",
    "    btn_start_runner = st.sidebar.button(\"Start Listening\")\n",
    "    if btn_start_runner:\n",
    "        with st.spinner('Wait for it...'):\n",
    "            try:\n",
    "                start_local_process(coin_selection,refresh_rate)\n",
    "            except:\n",
    "                Exception(\"Error\")\n",
    "            sleep(3)\n",
    "        st.sidebar.success('Listening to Tweets now..!') \n",
    "        st.sidebar.warning(\"The page will refresh in 30 seconds. Please wait\")\n",
    "\n",
    "#Show the actual Status of the Process in Sidebar\n",
    "st.sidebar.markdown(process_status_text,unsafe_allow_html=True)\n",
    "\n",
    "page_refresh_rate=st_autorefresh(interval= refresh_rate*60*1000, key=\"page_refresh_rate\")\n",
    "\n",
    "## Call functions\n",
    "dataframes = get_json_data()\n",
    "find_pid()\n",
    "show_data()\n",
    "\n",
    "#A Button for Explanation\n",
    "# st.sidebar.markdown(\"---\")\n",
    "# btn_whats_this = st.sidebar.button(\"What's this?\")\n",
    "# if btn_whats_this:\n",
    "#     with st.expander(\"What's this?\"):\n",
    "#         st.write(\"This is a Programm that listens to the Sentiment of Tweets from Twitter and visualises it. Createdy by Moerv\")\n",
    "#         img_to_my_pic = '<div align=\"center\"><a href=\"https://github.com/moerv9/sentiment\"><img src=\"https://github.com/moerv9.png\" alt=\"Github Profile\" width=\"200\"></div>'\n",
    "#         st.markdown(img_to_my_pic,unsafe_allow_html=True)\n",
    "        \n",
    "## Show the Tables of Data for each Coin             \n",
    "btn_show_datasets = st.sidebar.button(\"Show Datasets\")\n",
    "if btn_show_datasets:\n",
    "    try:\n",
    "        st.markdown(\"---\")\n",
    "        st.subheader(\"Datasets\")\n",
    "        for key, df in dataframes.items():\n",
    "            with st.expander(f\"Tweet Data for {key[:-5].upper()}\"):\n",
    "                st.dataframe(df.tail(5))\n",
    "    except:\n",
    "        Exception(\"Can't display data for right now\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'balance' not in st.session_state:\n",
    "        st.session_state['balance'] = balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a style.css to streamlit\n",
    "\n",
    "with open('style.css') as f:\n",
    "    st.markdown(f'<style>{f.read()}</style>', unsafe_allow_html=True)\n",
    "    \n",
    "# style.css\n",
    "# div.element-container.css-15deyup.e1tzin5v3{\n",
    "\n",
    "\n",
    "# } "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kucoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Trans. Volume</th>\n",
       "      <th>Trans. Amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-08-25 12:16:00</th>\n",
       "      <td>431.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-25 12:15:00</th>\n",
       "      <td>431.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-25 12:14:00</th>\n",
       "      <td>431.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-25 12:13:00</th>\n",
       "      <td>431.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-25 12:12:00</th>\n",
       "      <td>431.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-24 14:04:00</th>\n",
       "      <td>431.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-24 14:03:00</th>\n",
       "      <td>431.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-24 14:02:00</th>\n",
       "      <td>431.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-24 14:01:00</th>\n",
       "      <td>431.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>0.00567</td>\n",
       "      <td>2.44377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-24 14:00:00</th>\n",
       "      <td>431.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>431.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1337 rows Ã 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Open  Close   High    Low  Trans. Volume  Trans. Amount\n",
       "Time                                                                         \n",
       "2022-08-25 12:16:00  431.0  431.0  431.0  431.0        0.00001        0.00431\n",
       "2022-08-25 12:15:00  431.0  431.0  431.0  431.0        0.00001        0.00431\n",
       "2022-08-25 12:14:00  431.0  431.0  431.0  431.0        0.00001        0.00431\n",
       "2022-08-25 12:13:00  431.0  431.0  431.0  431.0        0.00000        0.00000\n",
       "2022-08-25 12:12:00  431.0  431.0  431.0  431.0        0.00000        0.00000\n",
       "...                    ...    ...    ...    ...            ...            ...\n",
       "2022-08-24 14:04:00  431.0  431.0  431.0  431.0        0.00000        0.00000\n",
       "2022-08-24 14:03:00  431.0  431.0  431.0  431.0        0.00000        0.00000\n",
       "2022-08-24 14:02:00  431.0  431.0  431.0  431.0        0.00000        0.00000\n",
       "2022-08-24 14:01:00  431.0  431.0  431.0  431.0        0.00567        2.44377\n",
       "2022-08-24 14:00:00  431.0  431.0  431.0  431.0        0.00000        0.00000\n",
       "\n",
       "[1337 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kucoin.client import Client as kucoinClient\n",
    "import pandas as pd\n",
    "from datetime import datetime,timedelta\n",
    "from time import sleep\n",
    "\n",
    "import os\n",
    "#Config\n",
    "os.sys.path.insert(0,\"/Users/marvinottersberg/Documents/GitHub/sentiment\")\n",
    "from config import ConfigKucoin\n",
    "kconf=ConfigKucoin()\n",
    "\n",
    "kClient = kucoinClient(kconf.KUCOIN_SUB_KEY, kconf.KUCOIN_SUB_SECRET,kconf.KUCOIN_SUB_PASS,sandbox=True)\n",
    "# dates = pd.to_datetime(['2019-01-15 13:30:00'])\n",
    "# (dates - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1s')\n",
    "start_time = pd.Timestamp('2022-08-24 12:00:00').timestamp()\n",
    "end_time = pd.Timestamp(datetime.now()).timestamp()\n",
    "klines = kClient.get_kline_data(symbol=\"BTC-USDT\",kline_type=\"1min\",start=int(start_time),end=int(end_time))\n",
    "frame = pd.DataFrame(klines)\n",
    "frame = frame.iloc[:,:7]\n",
    "frame.columns= [\"Time\",\"Open\",\"Close\",\"High\",\"Low\",\"Trans. Volume\",\"Trans. Amount\"]\n",
    "frame = frame.set_index(\"Time\")\n",
    "frame.index = pd.to_datetime(frame.index,unit=\"s\")\n",
    "frame.index = frame.index + timedelta(hours=2) #utc to local\n",
    "frame = frame.astype(float)\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# btc_price = kClient.get_fiat_prices(symbol=\"BTC\")\n",
    "# print(btc_price)\n",
    "# current_btc_balance_value = float(btc_balance) * float(btc_price)\n",
    "# # get market depth\n",
    "# depth = client.get_order_book('BTC-USDT')\n",
    "# get symbol klines\n",
    "#klines = client.get_kline_data('BTC-USDT',\"1hour\") # buy base:btc, sell quote: usdt // intervals: 1min, 3min, 5min, 15min, 30min, 1hour, 2hour, 4hour, 6hour, 8hour, 12hour, 1day, 1week // start: Start time as unix timestamp (optional) default start of day in UTC\n",
    "#print(klines)\n",
    "\n",
    "# items = kClient.get_account_activity() #MACHT NIX\n",
    "# print(\"items\")\n",
    "# print(items)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#get orders\n",
    "\n",
    "'''\n",
    "{'currentPage': 1, 'pageSize': 50, 'totalNum': 2, 'totalPage': 1, 'items': [{'id': '62f3929a0091a60001fe1420', 'symbol': 'BTC-USDT', 'opType': 'DEAL', 'type': 'market', 'side': 'sell', 'price': '0', 'size': '0.0005', 'funds': '0', 'dealFunds': '0.206', 'dealSize': '0.0005', 'fee': '0.000206', 'feeCurrency': 'USDT', 'stp': '', 'stop': '', 'stopTriggered': False, 'stopPrice': '0', 'timeInForce': 'GTC', 'postOnly': False, 'hidden': False, 'iceberg': False, 'visibleSize': '0', 'cancelAfter': 0, 'channel': 'API', 'clientOid': '1619045506084ef4aaa4316b59f931ef', 'remark': None, 'tags': None, 'isActive': False, 'cancelExist': False, 'createdAt': 1660129946834, 'tradeType': 'TRADE'}, {'id': '62f3912b0091a60001fe12c3', 'symbol': 'BTC-USDT', 'opType': 'DEAL', 'type': 'market', 'side': 'buy', 'price': '0', 'size': '0.0005', 'funds': '0', 'dealFunds': '11.553', 'dealSize': '0.0005', 'fee': '0.011553', 'feeCurrency': 'USDT', 'stp': '', 'stop': '', 'stopTriggered': False, 'stopPrice': '0', 'timeInForce': 'GTC', 'postOnly': False, 'hidden': False, 'iceberg': False, 'visibleSize': '0', 'cancelAfter': 0, 'channel': 'API', 'clientOid': 'd263b95e9a4740debc9c0de05d95fde4', 'remark': None, 'tags': None, 'isActive': False, 'cancelExist': False, 'createdAt': 1660129579713, 'tradeType': 'TRADE'}]}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price\n",
      "{'BTC': '23339.55659277'}\n",
      "{'currentPage': 1, 'pageSize': 50, 'totalNum': 0, 'totalPage': 0, 'items': []}\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#%pip install python-kucoin\n",
    "from socketserver import UDPServer\n",
    "from kucoin.client import Client as kucoinClient\n",
    "import pandas as pd\n",
    "from datetime import datetime,timedelta\n",
    "from time import sleep\n",
    "\n",
    "import os\n",
    "#Config\n",
    "os.sys.path.insert(0,\"/Users/marvinottersberg/Documents/GitHub/sentiment\")\n",
    "from config import ConfigKucoin\n",
    "kconf=ConfigKucoin()\n",
    "\n",
    "kClient = kucoinClient(kconf.KUCOIN_SUB_KEY, kconf.KUCOIN_SUB_SECRET,kconf.KUCOIN_SUB_PASS,sandbox=True)\n",
    "#kClient = kucoinClient(kconf.KUCOIN_KEY, kconf.KUCOIN_SECRET,kconf.KUCOIN_PASS,sandbox=True)\n",
    "\n",
    "\n",
    "tickers = kClient.get_ticker(symbol=\"BTC-USDT\")\n",
    "price = kClient.get_fiat_prices(symbol=\"BTC\",base=\"USD\")\n",
    "print(\"price\")\n",
    "print(price)\n",
    "# btc_price = tickers[\"bestAsk\"]\n",
    "# print(tickers)\n",
    "# print(\"prices\")\n",
    "# print(btc_price)\n",
    "\n",
    "\n",
    "\n",
    "# accounts = kClient.get_accounts(account_type=\"trade\")\n",
    "# usdt_balance = float(accounts[0][\"balance\"]) #for Main Client\n",
    "# btc_balance = float(accounts[1][\"balance\"]) #for Main client\n",
    "# btc_in_usdt = float(btc_balance) * float(btc_price)\n",
    "# #print(f\"USDT Balance: {usdt_balance} $\")\n",
    "#print(f\"BTC Balance: {btc_balance} ({btc_in_usdt} $)\")\n",
    "\n",
    "\n",
    "# priceInc = 0.00000001\n",
    "# #usdt_balance = 4512.02505334\n",
    "# funds = int(usdt_balance*0.05)\n",
    "#sellfunds = round(btc_balance * 0.25,5)\n",
    "#print(sellfunds)\n",
    "#print(0.1192484*0.25)\n",
    "\n",
    "# test function\n",
    "# while True:\n",
    "#     if btc_balance > 0.0005:\n",
    "#         sellfunds = round(btc_balance * 0.25,5)\n",
    "#     elif btc_balance == 0.0:\n",
    "#         break\n",
    "#     else:\n",
    "#         sellfunds = btc_balance\n",
    "#     print(f\"Selling for {sellfunds}\")\n",
    "#     order = kClient.create_market_order(symbol = \"BTC-USDT\", side = kClient.SIDE_SELL, size = sellfunds)\n",
    "#     print(f\"SELL ORDER executed with {sellfunds} at {datetime.now()}\")\n",
    "#     if order:\n",
    "#         break\n",
    "#     else:\n",
    "#         sellfunds = btc_balance\n",
    "\n",
    "\n",
    "#order = kClient.create_market_order('BTC-USDT', kClient.SIDE_BUY, size= int(usdt_balance *0.09))\n",
    "# print(order[\"orderId\"])\n",
    "# print(type(order[\"orderId\"]))\n",
    "\n",
    "\n",
    "#TODO: In dict und dann dataframe convertieren NACH ORDER AUSGEFÃHRT TESTEN\n",
    "orders = kClient.get_orders(symbol='BTC-USDT')\n",
    "print(orders)\n",
    "d = []\n",
    "for i in orders[\"items\"]:#order[\"orderId\"]:\n",
    "    time = pd.to_datetime(i[\"createdAt\"],unit=\"ms\",utc=True) + timedelta(hours=2)\n",
    "    fee =  i[\"fee\"]\n",
    "    d.append([pd.to_datetime(i[\"createdAt\"],unit=\"ms\",utc=True) + timedelta(hours=2),i[\"symbol\"], i[\"side\"],i[\"size\"],i[\"funds\"], i[\"fee\"],i[\"isActive\"], i[\"cancelExist\"],i[\"id\"]])\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data=d)#,columns=[\"time\",\"symbol\",\"side\",\"size\",\"funds\",\"fee\",\"isActive\",\"cancelExist\",\"id\"])\n",
    "# # #df.set_index(\"time\",inplace=True)\n",
    "# # print(df[\"time\"][0])\n",
    "# # print(fee)\n",
    "# # print(type(time))\n",
    "print(df)\n",
    "\n",
    "# print(pd.Timestamp(datetime.now() - timedelta(hours = 3)))\n",
    "\n",
    "# for i in range(len(kClient.get_symbols())):\n",
    "#     print(\"{} : {}\".format(i,kClient.get_symbols()[i][\"symbol\"]))\n",
    "#kClient.get_symbols()[11]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20169.69000000\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# Defining Binance API URL\n",
    "url = \"https://api.binance.com/api/v3/ticker/price?symbol=BTCUSDT\"\n",
    "data = requests.get(url)\n",
    "data = data.json()\n",
    "btc_price = data[\"price\"]\n",
    "print(btc_price)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current BTC Price: 4088\n",
      "[{'id': '62f38fa729c69200014b6210', 'currency': 'USDT', 'type': 'trade', 'balance': '38989.59938855', 'available': '38989.59938855', 'holds': '0'}, {'id': '62f3897529c69200014b61f0', 'currency': 'BTC', 'type': 'main', 'balance': '4.52141859', 'available': '4.52141859', 'holds': '0'}, {'id': '62f3912bf1ee300001ae57a7', 'currency': 'BTC', 'type': 'trade', 'balance': '1.95224726', 'available': '1.95224726', 'holds': '0'}, {'id': '62f389750091a60001e77c77', 'currency': 'USDT', 'type': 'main', 'balance': '280.31363152', 'available': '280.31363152', 'holds': '0'}, {'id': '62f389750091a60001e77c79', 'currency': 'ETH', 'type': 'main', 'balance': '50', 'available': '50', 'holds': '0'}]\n",
      "USDT Balance: 38989.59938855 $\n",
      "BTC Balance: 4.52141859 (18483.55919592 $)\n",
      "1949.47997\n",
      "Sell all\n"
     ]
    }
   ],
   "source": [
    "## For DOcumentation\n",
    "from kucoin.client import Client as kucoinClient\n",
    "import re\n",
    "from time import sleep\n",
    "kClient = kucoinClient(kconf.KUCOIN_KEY, kconf.KUCOIN_SECRET,kconf.KUCOIN_PASS,sandbox=True)\n",
    "#kClient = kucoinClient(kconf.KUCOIN_SUB_KEY, kconf.KUCOIN_SUB_SECRET,kconf.KUCOIN_SUB_PASS,sandbox=True)\n",
    "\n",
    "tickers = kClient.get_ticker(symbol=\"BTC-USDT\")\n",
    "btc_price = tickers[\"bestAsk\"]\n",
    "print(f\"Current BTC Price: {btc_price}\")\n",
    "\n",
    "accounts = kClient.get_accounts(account_type=\"trade\")\n",
    "accounts = kClient.get_accounts()\n",
    "print(accounts)\n",
    "\n",
    "\n",
    "usdt_balance = accounts[0][\"balance\"] #for Main Client\n",
    "btc_balance = accounts[1][\"balance\"] #for Main client\n",
    "#kcs_balance \n",
    "btc_in_usdt = float(btc_balance) * float(btc_price)\n",
    "print(f\"USDT Balance: {usdt_balance} $\")\n",
    "print(f\"BTC Balance: {btc_balance} ({btc_in_usdt} $)\")\n",
    "unds = round(float(usdt_balance)*0.05,5)\n",
    "print(unds)\n",
    "\n",
    "print(\"Sell all\")\n",
    "funds = re.match(r'\\d+.\\d{3}', str(btc_balance)).group(0)\n",
    "\n",
    "order = kClient.create_market_order('KCS-USDT', kClient.SIDE_BUY,size = 1)\n",
    "# sleep(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marvinottersberg/opt/anaconda3/envs/dontbesentimental/lib/python3.9/site-packages/pandas/io/sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-12 19:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'>\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "DB_URL=\"postgresql://wjhgxflbnaygwb:65c900f1fb2e477ae1fa161e543db8b81d613fe7b8b6fbdb1f2e370bd07a6017@ec2-54-228-218-84.eu-west-1.compute.amazonaws.com:5432/db1m9hb4f699st\"\n",
    "conn = psycopg2.connect(DB_URL, sslmode=\"require\")\n",
    "\n",
    "query = \"select * from trade_data where id > 6 order by id desc limit 1;\"\n",
    "df_trades = pd.read_sql(query, conn)\n",
    "last_trade_time = df_trades[\"avgTime\"][0]\n",
    "\n",
    "print(last_trade_time)\n",
    "print(type(last_trade_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # dt = datetime.now() - timedelta(hours = 3)\n",
    "        # dt = dt.replace(tzinfo=timezone.utc)\n",
    "        # self.trade_exec_at = dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apscheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apscheduler.schedulers.background import BackgroundScheduler\n",
    "sched = BackgroundScheduler()\n",
    "\n",
    "@sched.scheduled_job('interval', minutes=30)\n",
    "def timed_job():\n",
    "    print('This job is run every three minutes.')\n",
    "\n",
    "@sched.scheduled_job('cron', day_of_week='mon-sun', hour=17)\n",
    "def scheduled_job():\n",
    "    print('This job is run every weekday at 5pm.')\n",
    "\n",
    "\n",
    "sched.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.21"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import regex as re\n",
    "average = -0.21237832849\n",
    "#average = '%.3f'%(average)\n",
    "#average = re.match(r'\\d+.\\d{3}', str(average)).group(0)\n",
    "\n",
    "average\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_DF_by_time(df,time_frame):\n",
    "    \"\"\"Returns Dataframe for the past hours specified in time_frame\n",
    "\n",
    "    Args:\n",
    "        df (_type_): Dataframe to split\n",
    "        time_frame (_type_): timeframe to look at\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: in the given timeframe\n",
    "    \"\"\"\n",
    "    #print(\"split df by time:\")\n",
    "    #print(df.head(10))\n",
    "    if \"Timestamp\" in df.columns:\n",
    "        df.index = df[\"Timestamp\"]\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    timedelt = datetime.now() - timedelta(hours=time_frame,minutes=15)\n",
    "    mask = (df.index > timedelt)\n",
    "    df = df.loc[mask]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "CEST\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from dateutil import tz\n",
    "\n",
    "# METHOD 1: Hardcode zones:\n",
    "from_zone = tz.gettz('UTC')\n",
    "to_zone = tz.gettz('Europe/Berlin')\n",
    "\n",
    "# METHOD 2: Auto-detect zones:\n",
    "# from_zone = tz.tzutc()\n",
    "# to_zone = tz.tzlocal()\n",
    "\n",
    "utc = datetime.utcnow()\n",
    "print(utc.tzname())\n",
    "#utc = datetime.strptime('2011-01-21 02:37:21', '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Tell the datetime object that it's in UTC time zone since \n",
    "# datetime objects are 'naive' by default\n",
    "utc = utc.replace(tzinfo=from_zone)\n",
    "\n",
    "# Convert time zone\n",
    "central = utc.astimezone(to_zone)\n",
    "print(central.tzname())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('dontbesentimental')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f006eaa69a9e1242291392219277a0a973a697a6ded3a6ef5df3e91aa85b190b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
